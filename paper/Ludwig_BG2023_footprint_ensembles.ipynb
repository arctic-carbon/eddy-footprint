{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Flux tower footprint ensembles for Ludwig et al. Biogeosciences  \n",
    "\n",
    "This notebook contains code used in Ludwig S. M., L. Schiferl, J. Hung, S. M. Natali, R. Commane.\n",
    "In review. Biogeosciences. https://bg.copernicus.org/preprints/bg-2023-119/.  \n",
    "This notebook creates footprint models and convolves them with a landcover map.  \n",
    "\n",
    "It is written to work with the eddy covariance (EC) flux dataset: \"eddy_cov_C_fluxes_nofilter_YKD.csv\".  \n",
    "The mapping and convoling are site-specific.  \n",
    "This EC time-series has not been QC/QC'd or filtered (e.g. u* filtering). That happens at a later step.  \n",
    "\n",
    "Three analytical footprint models are used:\n",
    "\n",
    "1) Hsieh et al. 2000 with a 2D extension from Detto et al. 2006\n",
    "2) Kljun et al. 2015\n",
    "3) Kormann and Meixner et al. 2001\n",
    "\n",
    "Footprints are generated for each half-hour flux observation as rasters (.tif).  \n",
    "Each footprint raster is regridded to match the extent, projection, and resolution of the provided landcover map.  \n",
    "Each regridded footprint is summarized over landcover categories and concatenated in an exported .csv.\n",
    "\n",
    "Updated 04/02/2022\n",
    "Ludda Ludwig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from mpmath import gamma\n",
    "from osgeo import gdal\n",
    "from osgeo import osr\n",
    "import rasterio as rio\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy\n",
    "import xarray as xr\n",
    "from osgeo import gdalconst\n",
    "from osgeo import gdal_array\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"../paper/eddy_cov_C_fluxes_nofilter_YKD.csv\",\n",
    "    parse_dates=[1],\n",
    "    na_values=\"NA\",\n",
    "    delimiter=\" *, *\",\n",
    "    index_col=False,\n",
    "    engine=\"python\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace(\".\", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(\"datetime\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a 1-dimensional footprint for the fluxes following the methods of Hsieh et al. 2000. First define stability metric $\\zeta=z/L$: neutral conditions where |z/L|<0.02, stable where z/L>0.02, and unstable where z/L<-0.02. For this tower, z=2.5 m. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zm = 2.5\n",
    "cp = 1003  # J/K kg specific heat of air for constant pressure, 287 + gas constant of dry air J/kg K\n",
    "df[\"Lcalc\"] = -(\n",
    "    ((df.air_pressure) / (287 * (df.air_temperature + 273)))\n",
    "    * cp\n",
    "    * (df.u_**3)\n",
    "    * (273 + df.air_temperature)\n",
    ") / (0.41 * 9.8 * df.H)\n",
    "df[\"zeta\"] = zm / df.Lcalc\n",
    "df[\"D\"] = np.ones_like(df.zeta)\n",
    "df[\"P\"] = np.ones_like(df.zeta)\n",
    "df[\"psi_m_H\"] = np.ones_like(df.zeta)\n",
    "df[\"psi_m_zm\"] = np.ones_like(df.zeta)\n",
    "df[\"psi_m_klj\"] = np.ones_like(df.zeta)\n",
    "\n",
    "df[\"m\"] = np.ones_like(df.zeta)\n",
    "df[\"n\"] = np.ones_like(df.zeta)\n",
    "df[\"phi_m\"] = np.ones_like(df.zeta)\n",
    "df[\"phi_c\"] = np.ones_like(df.zeta)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define similarity constants D and P, and roughness length parameter psi_m based on stability metric:\n",
    "D = 0.28; P = 0.59 for unstable condition,\n",
    "D = 0.97; P = 1 for near neutral and neutral conditions,\n",
    "D = 2.44; P = 1.33 for stable condition.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine stability correction factors psi_m (diabatic integration of wind profile (Paulson 1970)), phi_c (scalar eddy diffusivity), and phi_m (non-dimensional wind shear Dyer 1974) used for calculating surface roughness length (znot) and other constants under different atmospheric stability conditions:\n",
    "\n",
    "\n",
    "If neutral, $$\\psi_m =0$$\n",
    "\n",
    "\n",
    "If stable, $$\\psi_m = -5\\zeta$$\n",
    "\n",
    "$$\\phi_c=\\phi_m=1+5\\zeta$$\n",
    "\n",
    "\n",
    "If unstable,\n",
    "$$\\psi_m = 2*log((1+x)/2)+log((1+x^2)/2)-2arctan(x)+\\pi/2,  x = (1-16\\zeta)^{0.25}$$\n",
    "$$\\phi_c=(1-16\\zeta)^{-0.5}$$\n",
    "$$\\phi_m=(1-16\\zeta)^{-0.25}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ex\"] = (1 - 16 * df.zeta) ** 0.25\n",
    "df[\"ex_klj\"] = (1 - 19 * df.zeta) ** 0.25\n",
    "\n",
    "df[\"psi_m_zm\"] = np.where(\n",
    "    (df[\"Lcalc\"] < 0),\n",
    "    -2 * np.log((1 + df.ex) / 2)\n",
    "    - np.log((1 + df.ex**2) / 2)\n",
    "    + 2 * np.arctan(df.ex)\n",
    "    - np.pi / 2,\n",
    "    df[\"psi_m_zm\"],\n",
    ")\n",
    "df[\"psi_m_zm\"] = np.where((df[\"Lcalc\"] > 0), 5 * df.zeta, df[\"psi_m_zm\"])\n",
    "\n",
    "df[\"psi_m_klj\"] = np.where((df[\"Lcalc\"] > 0), -5.3 * df.zeta, df[\"psi_m_klj\"])\n",
    "df[\"psi_m_klj\"] = np.where(\n",
    "    (df[\"Lcalc\"] < 0),\n",
    "    2 * np.log((1 + df.ex_klj) / 2)\n",
    "    + np.log((1 + df.ex_klj**2) / 2)\n",
    "    - 2 * np.arctan(df.ex_klj)\n",
    "    + np.pi / 2,\n",
    "    df[\"psi_m_klj\"],\n",
    ")\n",
    "\n",
    "df[\"phi_c\"] = np.where((df[\"Lcalc\"] > 0), 1 + 5 * df.zeta, df[\"phi_c\"])\n",
    "df[\"phi_c\"] = np.where(((df[\"Lcalc\"]) < 0), (1 - 16 * df.zeta) ** (-0.5), df[\"phi_c\"])\n",
    "df[\"phi_m\"] = np.where((df[\"Lcalc\"] > 0), 1 + 5 * df.zeta, df[\"phi_m\"])\n",
    "df[\"phi_m\"] = np.where(((df[\"Lcalc\"]) < 0), (1 - 16 * df.zeta) ** (-0.25), df[\"phi_m\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define several other terms needed for calculating the footprint and fetch:\n",
    "\n",
    "$$z_{not} = z_m/(exp(0.41* windspeed/u^*+\\psi_m))$$\n",
    "$$z_u=z_m*ln(z_m/z_{not})-1+z_{not}/z_m$$\n",
    "$$\\mu=(1+m)/r$$\n",
    "$$\\xi=U*(z_m)^r/(r^2*0.41)$$\n",
    "$$r=2+m-n$$\n",
    "$$windspeed=U*z_m^m$$\n",
    "$$K=\\kappa*z_m^n=0.41u_*z_m/\\phi_c$$\n",
    "$$m=u_*\\phi_m/(0.41*windspeed)$$\n",
    "$$n=1/(1+5\\zeta)$$\n",
    "for $$L>0$$\n",
    "$$n=(1-24\\zeta)/(1-16\\zeta)$$ \n",
    "for $$L<0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating znot (run once):\n",
    "\n",
    "# neutral defined conservatively according to Hsieh as |zu/L|\n",
    "# df_znot=df[df.zeta<0.02]\n",
    "# df_znot=df_znot[df_znot.zeta>(-0.02)]\n",
    "# df_znot['znot']=zm/np.exp(df_znot.wind_speed*0.41/df_znot.u_)\n",
    "# df_znot.znot.describe() # mean is 0.0206, median is 0.00726, doesn't change much from using +/-0.02 or 0.04.\n",
    "# df_znot.psi_m_zm.describe() # mean is 0.03, median is 0.03\n",
    "# df.psi_m_zm.describe() #mean of whole dataset is 0.6, median is 1.\n",
    "znot = 0.0206"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"zu\"] = zm * (np.log(zm / znot) - 1 + znot / zm)\n",
    "df[\"zeta_H\"] = df.zu / df.Lcalc\n",
    "df[\"D\"] = np.where((df[\"zeta_H\"] < (-0.02)), 0.28, df[\"D\"])\n",
    "df[\"D\"] = np.where((df[\"zeta_H\"] > 0.02), 2.44, df[\"D\"])\n",
    "df[\"D\"] = np.where((np.abs(df[\"zeta_H\"]) < 0.02), 0.97, df[\"D\"])\n",
    "df[\"P\"] = np.where((df[\"zeta_H\"] < (-0.02)), 0.59, df[\"P\"])\n",
    "df[\"P\"] = np.where((df[\"zeta_H\"] > 0.02), 1.33, df[\"P\"])\n",
    "df[\"P\"] = np.where((np.abs(df[\"zeta_H\"]) < 0.02), 1, df[\"P\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"m\"] = df.u_ * df.phi_m / (0.41 * df.wind_speed)\n",
    "df[\"n\"] = np.ones_like(df.zeta)\n",
    "df[\"n\"] = np.where((df[\"Lcalc\"] > 0), 1 / (1 + 5 * df.zeta), df[\"n\"])\n",
    "df[\"n\"] = np.where(\n",
    "    ((df[\"Lcalc\"]) < 0), (1 - 24 * df.zeta) / (1 - 16 * df.zeta), df[\"n\"]\n",
    ")\n",
    "df[\"U\"] = df.wind_speed / (zm**df.m)\n",
    "# df['U1']=(np.log(zm/znot)+df.psi_m_zm)*df.u_/(0.41*zm**df.m)\n",
    "df[\"kappa\"] = 0.41 * df.u_ * zm / (df.phi_c * zm**df.n)\n",
    "df[\"r\"] = 2 + df.m - df.n\n",
    "df[\"xi\"] = (df.U * zm**df.r) / (df.kappa * df.r**2)\n",
    "df[\"mu\"] = (1 + df.m) / df.r"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the dataset to pull only times when the wind is coming from the direction over the lake and there are good methane fluxes. Pick one time point to continue the footprint analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.reset_index()\n",
    "df3 = df2[df2.co2_flux.notnull()]\n",
    "df3 = df3[df3.Lcalc.notnull()]\n",
    "df3 = df3[df3.v_var.notnull()]\n",
    "df3.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the crosswind integrated footprint along dimension x up to the 90% fetch length for a given half hour block:\n",
    "Following Hsieh et al. 2000:\n",
    "$$Fy=(1/(x^2* 0.041^2))* D* {zu^P}* |L|^{1-P}* exp(-D* zu^P* |L|^{1-p}/(x* 0.41^2)$$\n",
    "Following Karmann and Meixner 2001:\n",
    "$$Fy=(1/\\Gamma(\\mu))(\\xi^\\mu/x^{1+\\mu})e^{-\\xi/x}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Extend the 1-D footprint into a 2-D footprint using the lateral dispersion, for a given half-hour:\n",
    "Hsieh et al. 2000:\n",
    "$$\\sigma_y=(0.3* z_{not}* sqrt{\\sigma_v}/u^*)* ((x/z_{not})^{0.86})$$\n",
    "Forbich et al 2011 & Budischev et al. 2014 following Kormann and Meixner et al. 2001:\n",
    "$$\\sigma_y=sqrt{\\sigma_v}*x/u^{-}$$\n",
    "$$u^{-}=\\Gamma(\\mu)/\\Gamma(1/r)*(\\kappa r^2/U)^{m/r}*(Ux^{m/r})$$\n",
    "For both: Gaussian crosswind distribution function (Pasquill 1974):\n",
    "$$Dxy=(1/(\\sqrt{2* \\pi}* \\sigma_y))* exp((-0.5)* ((y/\\sigma_y)^2))$$\n",
    "$$Fxy=Fy*Dxy$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References for footprint models:\n",
    "Hsieh C., G. Katul, T. Chi. 2000. Advances in water resources\n",
    "Detto M., N. Montaldo, J. D. Albertson, M. Mancini, G. Katul. 2006. Water resources research\n",
    "Kanda M., M. Kanega, T. Kawai, R. Moriwaki. 2007. American meteorlogical society\n",
    "Sanz Rodrigo J., E. Cantero, B. Garcia, F. Borbon, U. Irigoyen, S. Lozano, P. M. Fernandes, R. A. Chavez. 2015. Journal of physics: conference series 625.\n",
    "Businger J. A., J. C. Wyngaard, Y. Izumi, E. F. Bradley. 1971. Journal of atmospheric sciences\n",
    "M. Golbanzi, C. L. Archer. 2019. Advances in meteorology.\n",
    "R. Sozzi, M. Favaron. 1998. Journal of applied meteorology."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an array with lat long and georeference the footprint. The tower is located at 593402,6792413  in EPSG 32603, i.e. UTM 3N."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn the first footprint array into a raster for export.\n",
    "Next the raster is loaded and shifted so the tower is at the correct placement.\n",
    "Then it is re-gridded to the same ROI for all footprints and the landcover map.\n",
    "Then it is masked by covertype, and patch influence sums are calculated.\n",
    "Finally the rest of the dataset are looped through appending to create summarized footprint influence datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### create subset for footprint making loop:\n",
    "df4 = df3[df3.datetime > \"2019-07-20 11:00:00\"]\n",
    "df4 = df4[df4.datetime < \"2019-07-20 12:00:00\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For KM and Hsieh footprints\n",
    "\n",
    "match_extent = \"landcover_footprint_extent.tif\"\n",
    "match_ds = gdal.Open(match_extent, gdalconst.GA_ReadOnly)\n",
    "match_proj = match_ds.GetProjection()\n",
    "match_gt = match_ds.GetGeoTransform()\n",
    "wide = match_ds.RasterXSize\n",
    "high = match_ds.RasterYSize\n",
    "tower_y = 6792413\n",
    "tower_x = 593402\n",
    "\n",
    "for index, row in df4.iterrows():\n",
    "    x = np.linspace(1, 1000, 1000)\n",
    "    y = np.linspace(-250, 250, 500)\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    Fy_H = (\n",
    "        (1 / (0.41 * 0.41 * x * x))\n",
    "        * row.D\n",
    "        * (row.zu**row.P)\n",
    "        * (np.abs(row.Lcalc) ** (1 - row.P))\n",
    "        * np.exp(\n",
    "            (-row.D * (row.zu**row.P) * (np.abs(row.Lcalc) ** (1 - row.P)))\n",
    "            / (0.41 * 0.41 * x)\n",
    "        )\n",
    "    )\n",
    "    Fy_ZM = (\n",
    "        (1 / (float(gamma(row.mu))))\n",
    "        * (row.xi**row.mu)\n",
    "        / (x ** (1 + row.mu))\n",
    "        * np.exp(-row.xi / x)\n",
    "    )\n",
    "    sigma_y_H = (0.3 * znot * np.sqrt(row.v_var) / row.u_) * ((xx / znot) ** 0.86)\n",
    "    u_bar = (\n",
    "        float(gamma(row.mu))\n",
    "        / (float(gamma(1 / row.r)))\n",
    "        * ((row.kappa * (row.r**2) / row.U) ** (row.m / row.r))\n",
    "        * (row.U * (xx ** (row.m / row.r)))\n",
    "    )\n",
    "    sigma_y_ZM = np.sqrt(row.v_var) * xx / u_bar\n",
    "    Dxy_H = (1 / (np.sqrt(2 * np.pi) * sigma_y_H)) * np.exp(\n",
    "        (-0.5) * ((yy / sigma_y_H) ** 2)\n",
    "    )\n",
    "    Dxy_ZM = (1 / (np.sqrt(2 * np.pi) * sigma_y_ZM)) * np.exp(\n",
    "        (-0.5) * ((yy / sigma_y_ZM) ** 2)\n",
    "    )\n",
    "    Fxy_ZM = Fy_ZM * Dxy_ZM\n",
    "    Fxy_H = Fy_H * Dxy_H\n",
    "    dist1 = (xx**2 + yy**2) ** (0.5)\n",
    "    angle1 = np.arctan2(yy, xx)\n",
    "    xx_rot1 = dist1 * np.sin(row.wind_dir * np.pi / 180 - angle1)\n",
    "    yy_rot1 = dist1 * np.cos(row.wind_dir * np.pi / 180 - angle1)\n",
    "    long1 = xx_rot1 + tower_x\n",
    "    lat1 = yy_rot1 + tower_y\n",
    "    ysize1 = lat1.shape[0]\n",
    "    xsize1 = long1.shape[1]\n",
    "    rotation1 = (row.wind_dir + 90) * np.pi / 180\n",
    "    xres = 1\n",
    "    yres = 1\n",
    "    ulx = tower_x\n",
    "    uly = tower_y\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "\n",
    "    filenameH = \"%s_H.tif\" % row.filename\n",
    "    filenameZM = \"%s_ZM.tif\" % row.filename\n",
    "    srs = osr.SpatialReference()\n",
    "    srs.ImportFromProj4(\n",
    "        \"\"\"+proj=utm +zone=3 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs\"\"\"\n",
    "    )\n",
    "    gt1 = [\n",
    "        ulx,\n",
    "        -xres * np.cos(rotation1),\n",
    "        xres * np.sin(rotation1),\n",
    "        uly,\n",
    "        yres * np.sin(rotation1),\n",
    "        yres * np.cos(rotation1),\n",
    "    ]\n",
    "\n",
    "    dsH = driver.Create(filenameH, xsize1, ysize1, 1, gdal.GDT_Float32)\n",
    "    dsH.SetProjection(srs.ExportToWkt())\n",
    "    dsH.SetGeoTransform(gt1)\n",
    "    outband = dsH.GetRasterBand(1)\n",
    "    outband.WriteArray(Fxy_H)\n",
    "    dsH = None\n",
    "\n",
    "    dsZM = driver.Create(filenameZM, xsize1, ysize1, 1, gdal.GDT_Float32)\n",
    "    dsZM.SetProjection(srs.ExportToWkt())\n",
    "    dsZM.SetGeoTransform(gt1)\n",
    "    outband = dsZM.GetRasterBand(1)\n",
    "    outband.WriteArray(Fxy_ZM)\n",
    "    dsZM = None\n",
    "\n",
    "    footprintH = gdal.Open(filenameH, gdal.GA_Update)\n",
    "    hyp = lat1.shape[0] / 2\n",
    "    cornerN = (row.wind_dir) * np.pi / 180\n",
    "    West = np.cos(cornerN) * hyp\n",
    "    South = np.sin(cornerN) * hyp\n",
    "    gt2 = footprintH.GetGeoTransform()\n",
    "    gtl = list(gt2)\n",
    "    gtl[3] += South\n",
    "    gtl[0] -= West\n",
    "    new_geotransform = gtl\n",
    "    footprintH.SetGeoTransform(tuple(new_geotransform))\n",
    "    footprintH = None\n",
    "\n",
    "    footprintZM = gdal.Open(filenameZM, gdal.GA_Update)\n",
    "    hyp = lat1.shape[0] / 2\n",
    "    cornerN = (row.wind_dir) * np.pi / 180\n",
    "    West = np.cos(cornerN) * hyp\n",
    "    South = np.sin(cornerN) * hyp\n",
    "    gt2 = footprintZM.GetGeoTransform()\n",
    "    gtl = list(gt2)\n",
    "    gtl[3] += South\n",
    "    gtl[0] -= West\n",
    "    new_geotransform = gtl\n",
    "    footprintZM.SetGeoTransform(tuple(new_geotransform))\n",
    "    footprintZM = None\n",
    "\n",
    "    srcH = gdal.Open(filenameH, gdalconst.GA_ReadOnly)\n",
    "    src_proj = srcH.GetProjection()\n",
    "    src_gt = srcH.GetGeoTransform()\n",
    "    renamedH = \"%s_ex_H.tif\" % row.filename\n",
    "    dstH = gdal.GetDriverByName(\"GTiff\").Create(\n",
    "        renamedH, wide, high, 1, gdalconst.GDT_Float32\n",
    "    )\n",
    "    dstH.SetGeoTransform(match_gt)\n",
    "    dstH.SetProjection(match_proj)\n",
    "    gdal.ReprojectImage(srcH, dstH, src_proj, match_proj, gdalconst.GRA_Bilinear)\n",
    "    del dstH\n",
    "\n",
    "    srcZM = gdal.Open(filenameZM, gdalconst.GA_ReadOnly)\n",
    "    src_proj = srcZM.GetProjection()\n",
    "    src_gt = srcZM.GetGeoTransform()\n",
    "    renamedZM = \"%s_ex_ZM.tif\" % row.filename\n",
    "    dstZM = gdal.GetDriverByName(\"GTiff\").Create(\n",
    "        renamedZM, wide, high, 1, gdalconst.GDT_Float32\n",
    "    )\n",
    "    dstZM.SetGeoTransform(match_gt)\n",
    "    dstZM.SetProjection(match_proj)\n",
    "    gdal.ReprojectImage(srcZM, dstZM, src_proj, match_proj, gdalconst.GRA_Bilinear)\n",
    "    del dstZM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Kljun outside of their functions\n",
    "\n",
    "match_extent = \"landcover_footprint_extent.tif\"\n",
    "match_ds = gdal.Open(match_extent, gdalconst.GA_ReadOnly)\n",
    "match_proj = match_ds.GetProjection()\n",
    "match_gt = match_ds.GetGeoTransform()\n",
    "wide = match_ds.RasterXSize\n",
    "high = match_ds.RasterYSize\n",
    "tower_y = 6792413\n",
    "tower_x = 593402\n",
    "\n",
    "# Model parameters\n",
    "a_klj = 1.4524\n",
    "b_klj = -1.9914\n",
    "c_klj = 1.4622\n",
    "d_klj = 0.1359\n",
    "ac_klj = 2.17\n",
    "bc_klj = 1.66\n",
    "cc_klj = 20.0\n",
    "\n",
    "xstar_end = 30\n",
    "oln = 5000  # limit to L for neutral scaling\n",
    "k_klj = 0.4  # von Karman\n",
    "nx = 1000\n",
    "z0 = None\n",
    "h_klj = 1000\n",
    "\n",
    "# Scaled X* for crosswind integrated footprint\n",
    "xstar_ci_param = np.linspace(d_klj, xstar_end, nx + 2)\n",
    "xstar_ci_param = xstar_ci_param[1:]\n",
    "# Crosswind integrated scaled F*\n",
    "fstar_ci_param = (\n",
    "    a_klj\n",
    "    * (xstar_ci_param - d_klj) ** b_klj\n",
    "    * np.exp(-c_klj / (xstar_ci_param - d_klj))\n",
    ")\n",
    "ind_notnan = ~np.isnan(fstar_ci_param)\n",
    "fstar_ci_param = fstar_ci_param[ind_notnan]\n",
    "xstar_ci_param = xstar_ci_param[ind_notnan]\n",
    "\n",
    "# Scaled sig_y*\n",
    "sigystar_param = ac_klj * np.sqrt(\n",
    "    bc_klj * xstar_ci_param**2 / (1 + cc_klj * xstar_ci_param)\n",
    ")\n",
    "\n",
    "\n",
    "for index, row in df4.iterrows():\n",
    "    # wind drivers\n",
    "    umean = row.wind_speed\n",
    "    ol = row.L\n",
    "    sigmav = np.sqrt(row.v_var)\n",
    "    ustar = row.u_\n",
    "\n",
    "    # Real scale x and f_ci\n",
    "    if z0 is not None:\n",
    "        # Use z0\n",
    "        if ol <= 0 or ol >= oln:\n",
    "            xx = (1 - 19.0 * zm / ol) ** 0.25\n",
    "            psi_f = (\n",
    "                np.log((1 + xx**2) / 2.0)\n",
    "                + 2.0 * np.log((1 + xx) / 2.0)\n",
    "                - 2.0 * np.arctan(xx)\n",
    "                + np.pi / 2\n",
    "            )\n",
    "        elif ol > 0 and ol < oln:\n",
    "            psi_f = -5.3 * zm / ol\n",
    "\n",
    "        x_dim = xstar_ci_param * zm / (1.0 - (zm / h_klj)) * (np.log(zm / z0) - psi_f)\n",
    "        if np.log(zm / z0) - psi_f > 0:\n",
    "            x_ci = x_dim\n",
    "            f_ci = (\n",
    "                fstar_ci_param / zm * (1.0 - (zm / h_klj)) / (np.log(zm / z0) - psi_f)\n",
    "            )\n",
    "        else:\n",
    "            x_ci_max, x_ci, f_ci, x_2d, y_2d, f_2d = None\n",
    "    else:\n",
    "        # Use umean if z0 not available\n",
    "        x_dim = xstar_ci_param * zm / (1.0 - zm / h_klj) * (umean / ustar * k_klj)\n",
    "        if umean / ustar > 0:\n",
    "            x_ci = x_dim\n",
    "            f_ci = fstar_ci_param / zm * (1.0 - zm / h_klj) / (umean / ustar * k_klj)\n",
    "        else:\n",
    "            x_ci_max, x_ci, f_ci, x_2d, y_2d, f_2d = None\n",
    "\n",
    "    # Real scale sig_y\n",
    "    if abs(ol) > oln:\n",
    "        ol = -1e6\n",
    "    if ol <= 0:  # convective\n",
    "        scale_const = 1e-5 * abs(zm / ol) ** (-1) + 0.80\n",
    "    elif ol > 0:  # stable\n",
    "        scale_const = 1e-5 * abs(zm / ol) ** (-1) + 0.55\n",
    "    if scale_const > 1:\n",
    "        scale_const = 1.0\n",
    "    sigy = sigystar_param / scale_const * zm * sigmav / ustar\n",
    "    sigy[sigy < 0] = np.nan\n",
    "\n",
    "    # Real scale f(x,y)\n",
    "    dx = x_ci[2] - x_ci[1]\n",
    "    y_pos = np.arange(0, (len(x_ci) / 2.0) * dx * 1.5, dx)\n",
    "    f_pos = np.empty((len(f_ci), len(y_pos)))\n",
    "    f_pos[:] = np.nan\n",
    "    for ix in range(len(f_ci)):\n",
    "        f_pos[ix, :] = (\n",
    "            f_ci[ix]\n",
    "            * 1\n",
    "            / (np.sqrt(2 * np.pi) * sigy[ix])\n",
    "            * np.exp(-(y_pos**2) / (2 * sigy[ix] ** 2))\n",
    "        )\n",
    "\n",
    "    # Complete footprint for negative y (symmetrical)\n",
    "    y_neg = -np.fliplr(y_pos[None, :])[0]\n",
    "    f_neg = np.fliplr(f_pos)\n",
    "    y_dim = np.concatenate((y_neg[0:-1], y_pos))\n",
    "    f_dim = np.concatenate((f_neg[:, :-1].T, f_pos.T)).T\n",
    "\n",
    "    # Matrices for output\n",
    "    x_2d = np.tile(x_dim[:, None], (1, len(y_dim)))\n",
    "    y_2d = np.tile(y_dim.T, (len(x_dim), 1))\n",
    "    f_2d = f_dim\n",
    "\n",
    "    dist2 = (x_2d**2 + y_2d**2) ** (0.5)\n",
    "    angle2 = np.arctan2(y_2d, x_2d)\n",
    "    xx_rot2 = dist2 * np.sin(row.wind_dir * np.pi / 180 - angle2)\n",
    "    yy_rot2 = dist2 * np.cos(row.wind_dir * np.pi / 180 - angle2)\n",
    "    long2 = xx_rot2 + tower_x\n",
    "    lat2 = yy_rot2 + tower_y\n",
    "    ysize2 = lat2.shape[0]\n",
    "    xsize2 = long2.shape[1]\n",
    "    rotation2 = (row.wind_dir) * np.pi / 180\n",
    "    xres = 1\n",
    "    yres = 1\n",
    "    ulx = tower_x\n",
    "    uly = tower_y\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "\n",
    "    filenameKljun = \"%s_Kljun.tif\" % row.filename\n",
    "    srs = osr.SpatialReference()\n",
    "    srs.ImportFromProj4(\n",
    "        \"\"\"+proj=utm +zone=3 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs\"\"\"\n",
    "    )\n",
    "    gt2 = [\n",
    "        ulx,\n",
    "        -xres * np.cos(rotation2),\n",
    "        xres * np.sin(rotation2),\n",
    "        uly,\n",
    "        yres * np.sin(rotation2),\n",
    "        yres * np.cos(rotation2),\n",
    "    ]\n",
    "\n",
    "    dsKljun = driver.Create(filenameKljun, xsize2, ysize2, 1, gdal.GDT_Float32)\n",
    "    dsKljun.SetProjection(srs.ExportToWkt())\n",
    "    dsKljun.SetGeoTransform(gt2)\n",
    "    outband = dsKljun.GetRasterBand(1)\n",
    "    outband.WriteArray(f_2d)\n",
    "    dsKljun = None\n",
    "\n",
    "    footprintKljun = gdal.Open(filenameKljun, gdal.GA_Update)\n",
    "    hyp = lat2.shape[1] / 2\n",
    "    cornerN = (row.wind_dir) * np.pi / 180\n",
    "    West = np.cos(cornerN) * hyp\n",
    "    South = np.sin(cornerN) * hyp\n",
    "    gt2 = footprintKljun.GetGeoTransform()\n",
    "    gtl = list(gt2)\n",
    "    gtl[3] -= South\n",
    "    gtl[0] += West\n",
    "    new_geotransform = gtl\n",
    "    footprintKljun.SetGeoTransform(tuple(new_geotransform))\n",
    "    footprintKljun = None\n",
    "\n",
    "    src_Kljun = gdal.Open(filenameKljun, gdalconst.GA_ReadOnly)\n",
    "    src_proj = src_Kljun.GetProjection()\n",
    "    src_gt = src_Kljun.GetGeoTransform()\n",
    "    renamed_Kljun = \"%s_ex_Kljun.tif\" % row.filename\n",
    "    dst_Kljun = gdal.GetDriverByName(\"GTiff\").Create(\n",
    "        renamed_Kljun, wide, high, 1, gdalconst.GDT_Float32\n",
    "    )\n",
    "    dst_Kljun.SetGeoTransform(match_gt)\n",
    "    dst_Kljun.SetProjection(match_proj)\n",
    "    gdal.ReprojectImage(\n",
    "        src_Kljun, dst_Kljun, src_proj, match_proj, gdalconst.GRA_Bilinear\n",
    "    )\n",
    "    del dst_Kljun"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create mask for full extent, then load full footprint extents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = \"landcover_footprint_extent.tif\"\n",
    "landcover_array = gdal_array.LoadFile(image_name)\n",
    "print(landcover_array.shape)\n",
    "landcover_vect = landcover_array.reshape((611 * 241))\n",
    "test_y = np.linspace(1, 241, 241)\n",
    "test_x = np.linspace(1, 611, 611)\n",
    "test_xx, test_yy = np.meshgrid(test_x, test_y)\n",
    "plotr = plt.pcolormesh(test_xx, test_yy, landcover_array)\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create masks based on landcover:\n",
    "landcover_mask = dict()\n",
    "for index in range(0, 21):\n",
    "    landcover_mask[index] = np.ma.masked_where(\n",
    "        (landcover_vect == index), landcover_vect\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running it in 3 blocks of 5,000 observations since takes about half an hour per 5,000.\n",
    "# change range in iloc for defining df4 and name of csv export when running in batches\n",
    "# df4=df3.iloc[0:5000]\n",
    "\n",
    "# for Kljun footprint extents:\n",
    "\n",
    "# load footprints, unwrap, mask by landcovers, and summarize into an array:\n",
    "G_patch = np.zeros((1, 21), dtype=float)\n",
    "for index, row in df4.iterrows():\n",
    "    image_name = \"%s_ex_Kljun.tif\" % row.filename\n",
    "    dst_array_loop = gdal_array.LoadFile(image_name)\n",
    "    dst_row_loop = (dst_array_loop.reshape((611 * 241))) / np.sum(dst_array_loop)\n",
    "    ftp_masked = dict()\n",
    "    ftp_sums_loop = np.zeros((1, 21), dtype=float)\n",
    "    for itera in range(1, 21):\n",
    "        ftp_masked[itera] = np.ma.masked_array(\n",
    "            dst_row_loop, mask=np.invert(np.ma.getmask(landcover_mask[itera]))\n",
    "        )\n",
    "        ftp_class_sum = np.sum(ftp_masked[itera])\n",
    "        ftp_sums_loop[0, itera] = ftp_class_sum\n",
    "    G_patch = np.vstack((G_patch, ftp_sums_loop))\n",
    "G_patch = G_patch[1:, :]\n",
    "\n",
    "# write out array with attached filenames and dates from the eddy covariance fluxes\n",
    "df4.reset_index(drop=True, inplace=True)\n",
    "cover_type_num = np.linspace(1, G_patch.shape[1], G_patch.shape[1])\n",
    "res = list(map(int, cover_type_num))\n",
    "cover_names = list(map(str, res))\n",
    "G_patch_df = pd.DataFrame(G_patch, columns=cover_names)\n",
    "G_patch_df.reset_index(drop=True, inplace=True)\n",
    "G_patch_df2 = pd.concat([df4.filename, df4.datetime, G_patch_df], axis=1)\n",
    "G_patch_df2.to_csv(\"footprint_influence_sums_Kljun_dateversion_0-5000obs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running it in 3 blocks of 5,000 observations since takes about half an hour per 5,000.\n",
    "# change range in iloc for defining df4 and name of csv export when running in batches\n",
    "# df4=df3.iloc[0:5000]\n",
    "\n",
    "# for Hsieh footprint extents:\n",
    "\n",
    "# load footprints, unwrap, mask by landcovers, and summarize into an array:\n",
    "G_patch = np.zeros((1, 21), dtype=float)\n",
    "for index, row in df4.iterrows():\n",
    "    image_name = \"%s_ex_H.tif\" % row.filename\n",
    "    dst_array_loop = gdal_array.LoadFile(image_name)\n",
    "    dst_row_loop = (dst_array_loop.reshape((611 * 241))) / np.sum(dst_array_loop)\n",
    "    ftp_masked = dict()\n",
    "    ftp_sums_loop = np.zeros((1, 21), dtype=float)\n",
    "    for itera in range(1, 21):\n",
    "        ftp_masked[itera] = np.ma.masked_array(\n",
    "            dst_row_loop, mask=np.invert(np.ma.getmask(landcover_mask[itera]))\n",
    "        )\n",
    "        ftp_class_sum = np.sum(ftp_masked[itera])\n",
    "        ftp_sums_loop[0, itera] = ftp_class_sum\n",
    "    G_patch = np.vstack((G_patch, ftp_sums_loop))\n",
    "G_patch = G_patch[1:, :]\n",
    "\n",
    "# write out array with attached filenames and dates from the eddy covariance fluxes\n",
    "df4.reset_index(drop=True, inplace=True)\n",
    "cover_type_num = np.linspace(1, G_patch.shape[1], G_patch.shape[1])\n",
    "res = list(map(int, cover_type_num))\n",
    "cover_names = list(map(str, res))\n",
    "G_patch_df = pd.DataFrame(G_patch, columns=cover_names)\n",
    "G_patch_df.reset_index(drop=True, inplace=True)\n",
    "G_patch_df2 = pd.concat([df4.filename, df4.datetime, G_patch_df], axis=1)\n",
    "G_patch_df2.to_csv(\"footprint_influence_sums_Hsieh_dateversion_0-5000obs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running it in 3 blocks of 5,000 observations since takes about half an hour per 5,000.\n",
    "# change range in iloc for defining df4 and name of csv export when running in batches\n",
    "# df4=df3.iloc[0:5000]\n",
    "\n",
    "# for Kormann & Meixner  footprint extents:\n",
    "\n",
    "# load footprints, unwrap, mask by landcovers, and summarize into an array:\n",
    "G_patch = np.zeros((1, 21), dtype=float)\n",
    "for index, row in df4.iterrows():\n",
    "    image_name = \"%s_ex_ZM.tif\" % row.filename\n",
    "    dst_array_loop = gdal_array.LoadFile(image_name)\n",
    "    dst_row_loop = (dst_array_loop.reshape((611 * 241))) / np.sum(dst_array_loop)\n",
    "    ftp_masked = dict()\n",
    "    ftp_sums_loop = np.zeros((1, 21), dtype=float)\n",
    "    for itera in range(1, 21):\n",
    "        ftp_masked[itera] = np.ma.masked_array(\n",
    "            dst_row_loop, mask=np.invert(np.ma.getmask(landcover_mask[itera]))\n",
    "        )\n",
    "        ftp_class_sum = np.sum(ftp_masked[itera])\n",
    "        ftp_sums_loop[0, itera] = ftp_class_sum\n",
    "    G_patch = np.vstack((G_patch, ftp_sums_loop))\n",
    "G_patch = G_patch[1:, :]\n",
    "\n",
    "# write out array with attached filenames and dates from the eddy covariance fluxes\n",
    "df4.reset_index(drop=True, inplace=True)\n",
    "cover_type_num = np.linspace(1, G_patch.shape[1], G_patch.shape[1])\n",
    "res = list(map(int, cover_type_num))\n",
    "cover_names = list(map(str, res))\n",
    "G_patch_df = pd.DataFrame(G_patch, columns=cover_names)\n",
    "G_patch_df.reset_index(drop=True, inplace=True)\n",
    "G_patch_df2 = pd.concat([df4.filename, df4.datetime, G_patch_df], axis=1)\n",
    "G_patch_df2.to_csv(\"footprint_influence_sums_ZM_dateversion_0-5000obs.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
